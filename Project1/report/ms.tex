\documentclass{emulateapj}
%\documentclass[12pt,preprint]{aastex}

\usepackage{graphicx}
\usepackage{float}
\usepackage{amsmath}
\usepackage{epsfig,floatflt}
\usepackage{fourier}
\usepackage{listings}
\newcommand{\R}{\mathbb{R}}

\lstset{language=python,
    showspaces=false,
    extendedchars=true,
    breaklines=true,
    tabsize=2,
    basicstyle=\small\ttfamily,
    frame=single,
    columns=flexible,
    keepspaces=true,
    }


\DeclareMathAlphabet{\mathcal}{OMS}{cmsy}{m}{n}
\SetMathAlphabet{\mathcal}{bold}{OMS}{cmsy}{b}{n}


\begin{document}

\title{Project 1}

\author{Stig-Nicolai Foyn, Christer Dreierstad}

\email{stignicf@student.matnat.uio.no, chrisdre@student.matnat.uio.no}

\altaffiltext{1}{Institute of physics, University of
  Oslo, P.O.\ Box 1029 Blindern, N-0315 Oslo, Norway}


%\date{Received - / Accepted -}

\begin{abstract}
Comparing general and tailored methods for solving second order differential equations this study will present that producing a specialized method reduces the run time of a numerical solver without losing numerical accuracy. Reducing the floating point operations (FLOPS) will be proven efficient for large scale calculations.

  %State problem. Briefly describe method and data. Summarize main results.
\end{abstract}
\keywords{computational science --- numerical methods: error estimation, run time --- methods: numerical, tridiagonal matrices}

\section{Introduction}
\label{sec:introduction}
This study on generalized and tailored numerical algorithms will focus on how a differential equation is solved numerically most efficiently while not reducing the accuracy of the calculations. By comparing the run time and observing the numerical error of the calculations . To specify, the equation in question is the one dimensional Poisson equation:
%
\begin{equation*}
    {\nabla^{2}} \Phi = -4\pi \rho(r),
\end{equation*}
%
where $\Phi$ is the electrostatic potential generated by a localized charge distribution and $\rho$ is the charge density. This equation is used in electromagnetism, but in this case it was only necessary to analyze a normalized equation on the same form. Our normalized one dimensional Poisson equation can then be written as:
%
\begin{equation}\label{eq:-u''}
    -\frac{du^2}{dx^2} = f(x).
\end{equation}

Further rewriting this as a set of linear equation will allow us to solve it using our numerical algorithms. As generalized algorithm we will be using a pre-built function for LU-decomposition. Specializing our algorithm further for the problem we will make a generalized algorithm for any solving any tridiagonal matrix. Lastly we will make an algorithm completely tailored to our problem where the matrix elements are already specified. 

%Discuss background, physical importance and possibly some history of
%the problem that is being studied in this paper.


\section{Method}
\label{sec:method}
For the study we consider a solution for the source term $f(x)$ to be
%
\begin{gather*}\label{eq:f(x)}
    f(x) = 100e^{-10x},
\end{gather*}
%
which has a closed form solution 
%
\begin{gather}\label{eq:u(x)}
u(x) = 1-(1-e^{10})x-e^{-10x},
\end{gather}
%
which yields $-f(x)$ when taking the second derivative. 

We consider the one dimensional Poisson equation to uphold Dirichlet boundary conditions; $u(0)=u(1)=0$, so $x \in [0,1]$. The second order derivative $u(x)$ can be represented as
%
\begin{gather}\label{eq:du/dx}
 -\frac{du^2}{dx^2} = -\left(\frac{u(x+h) + u(x-h) - 2u(x)}{h^2} + \mathcal{O}(h^2)\right),
\end{gather}
%
where h is the step size. 

\subsection{Numerical representation}
By approximating equation \eqref{eq:du/dx} and discretizing over x we get
%
\begin{gather*}
    -\frac{du^2}{dx^2} = -\frac{u_{i+1} + u_{i-1} - 2u_i}{h^2} = f(x_i) = f_i.
\end{gather*}
%
Where the step size $h = 1/(n+1)$. When calculating $x_i = i\times h$ the calculations runs over $1$ to $n+1$, such that the last
%
\begin{gather}
    x_{n+1} = (n+1)h = (n+1)/(n+1) = 1,
\end{gather}
%
which ensures that $x \in [0,1]$. To simplify the calculations and reduce the FLOPS, we multiply the above equation by $h^2$ and rewrite $f'_i = h^2f_i = h^2 100 e^{-10x_i}$, such that the final discretized equation for solving equation \eqref{eq:-u''} is
%
\begin{gather}\label{eq:u_discretized}
    -\left(u_{i-1} - 2u_i + u_{i+1}\right) = f'_i.
\end{gather}
%
The linear combination above can be represented by a matrix vector multiplication. The matrix will consist of the coefficients of the $u_i$'s along the central, upper and lower diagonal, making up a tridiagonal matrix. The coefficient, after taking the outer sign of the left hand side of equation \eqref{eq:u_discretized} into consideration, are -1, 2 and -1 respectively. The vector will consist of the values of the $u_i$'s. The matrix representation will therefore be on the following form:
%
\[ \boldsymbol{Au} =
\begin{array}{c}
\begin{bmatrix}\label{eq:Au=f}
b_1     & c_1           & 0         & \dots     & \dots     & 0 \\
a_1     & b_2           & c_2       & 0         & \dots     & \dots \\
0       & a_2           & b_3       & c_3       & 0     & \dots\\
\dots  &  0            & a_3       & b_4       & \dots    & 0 \\
\dots  & \dots        & 0 & \dots    & \dots    & c_{n-1} \\
0       & \dots         & \dots         & 0         & a_{n-1}   & b_n   \\
\end{bmatrix}
\begin{bmatrix}
u_1 \\
u_2 \\
\dots \\
\dots \\
\dots \\
u_n
\end{bmatrix}
=
\begin{bmatrix}
f'_1 \\
f'_2 \\
\dots \\
\dots \\
\dots \\
f'_n
\end{bmatrix}
\end{array}
= \boldsymbol{f'_i}.
\]
%
Since we are considering fixed end points for $u$ we do not include $i = 0$ and $i = n+1$ in the calculations for updating the $u_i$'s. 

\subsection{General algorithm}
We consider the matrix $\boldsymbol{A}$ to consist of three vectors $\boldsymbol{a}$, $\boldsymbol{b}$ and $\boldsymbol{c}$ consisting of all $a_i$, $b_i$ and $c_i$ respectively. To solve the matrix equation we perform a forward and a backward substitution of $\boldsymbol{A}$ and $\boldsymbol{f'}$ respectively.

In order to forward substitute $\boldsymbol{A}$, the matrix must be upper triangular, which is done by Gaussian elimination. An example with a $4x4$-matrix $\boldsymbol{E}$ and two $4x1$ vectors $x$ and $g$ follows to show the algorithm that are to be presented later. Consider 
%
\[ \boldsymbol{Ex} =
\begin{array}{c}
\begin{bmatrix}\label{eq:Au=f}
b_1     & c_1           & 0         & 0 \\
a_1     & b_2           & c_2       & 0       \\
0       & a_2           & b_3       & c_3    \\
0  &  0            & a_3       & b_4     \\
\end{bmatrix}
\begin{bmatrix}
x_1 \\
x_2 \\
x_3 \\
x_4 \\
\end{bmatrix}
=
\begin{bmatrix}
g_1 \\
g_2 \\
g_3 \\
g_4
\end{bmatrix}
\end{array}
= \boldsymbol{g}.
\]
%
Performing Gaussian elimination we multiply the first row of $\boldsymbol{E}$ by $a_1/b_1$
%
\begin{gather*}
    \frac{a_1}{b_1}\begin{bmatrix} b_1 & c_1 & 0 & 0 \end{bmatrix} =  \begin{bmatrix} a_1 & \frac{a_1 c_1}{b_1} & 0 & 0\end{bmatrix},
\end{gather*}
and then subtract this from the second row:
%
\begin{gather*}
    \begin{bmatrix} a_1 & b_2 & c_2 & 0 \end{bmatrix} - \begin{bmatrix} a_1 & \frac{a_1 c_1}{b_1} & 0 & 0\end{bmatrix} = \begin{bmatrix} 0 & b2 - \frac{a_1 c_1}{b_1} & c_2 & 0 \end{bmatrix}.
\end{gather*}
%
With these operations the matrix $\boldsymbol{E}$ now reads
%
\[ \boldsymbol{E} =
\begin{array}{c}
\begin{bmatrix}
b_1     & c_1           & 0         & 0 \\
0 & b2 - \frac{a_1 c_1}{b_1} & c_2 & 0      \\
0       & a_2           & b_3       & c_3    \\
0  &  0            & a_3       & b_4    
\end{bmatrix},
\end{array}
\]
%
where the substitution $\Tilde{b}_2 = b_2-\frac{a_1c_1}{b_1}$ is introduced. This is performed on each of the lower triangular elements such that the end result is a upper triangular matrix
%
\[ \boldsymbol{E} =
\begin{array}{c}
\begin{bmatrix}
b_1     & c_1           & 0         & 0 \\
0 & \Tilde{b}_2 & c_2 & 0      \\
0       & 0           & \tilde{b}_3       & c_3    \\
0  &  0            & 0       & \tilde{b}_4
\end{bmatrix},
\end{array}
\]
%
where in general 
%
\begin{gather}\label{eq:b_i}
\tilde{b}_i = b_i - \frac{a_{i-1} c_{i-1}}{\tilde{b}_{i-1}},
\end{gather}
for $i \in [2,n+1]$. The above equation applies directly to $\boldsymbol{A}$. Since $\boldsymbol{E}$ is altered, the same operations must be applied to $\boldsymbol{g}$. Multiplying the first element of $\boldsymbol{g}$ by $a_1/b_1$ and subtracting this from the second element
%
\begin{gather*}
    \begin{bmatrix} g_2 \end{bmatrix} - \begin{bmatrix} \frac{g_1a_1}{b_1} \end{bmatrix}  = \begin{bmatrix} g_2 - \frac{g_1a_1}{b_1}\end{bmatrix}.
\end{gather*}
%
We then substitute $\tilde{g}_2 = g_2 - \frac{g_{1} a_{1}}{b_{1}}$. Applying this to $f'$ gives the general expression
%
\begin{gather}\label{eq:f_i}
    \tilde{f}_i = f'_i - \frac{\tilde{f}_{i-1} a_{i-1}}{\tilde{b}_{i-1}},
\end{gather}

for $i \in [2,n+1]$. The values for $\tilde{b}_i$ and $\tilde{f}_i$ are calculated through forward substitution. For $\tilde{b}_1$ and $\tilde{f}_1$ the value is not changed from the original $b_1$ and $f'_1$ respectively. Therefore the calculations are done over the interval $i \in [2,n+1]$ given the aforementioned initial conditions.

To calculate the values for $u_i$ we perform a backward substitution. We return to the example $\boldsymbol{E}\boldsymbol{x} = \boldsymbol{g}$, considering the Gauss eliminated matrix equation. For $i=4$ the equation reads
%
\begin{gather*}
    \tilde{b}_4 x_4 = \tilde{g}_4 \Rightarrow x_4 = \frac{\tilde{g}_4}{\tilde{b}_4},
\end{gather*}
%
and for $i=3$
%
\begin{gather*}
    \tilde{b}_3 x_3 + a_3 x_4 = \tilde{g_3} \Rightarrow \tilde{x}_3 = \frac{\tilde{g}_3 - a_3 x_4}{\tilde{b}_3}.
\end{gather*}
%
In general and applied to $\boldsymbol{A} \boldsymbol{u} = \boldsymbol{f'}$ the equation for $u_i$ reads:
%
\begin{gather}\label{eq:u_i}
    u_i = \frac{\tilde{f}_i - c_i u_{i+1}}{\tilde{b}_i}.
\end{gather}
%

\begin{lstlisting}
%Allocate dynamic memory for variables
double *a = new double[n+1]
%similar for other variables b, c, f-tilde, u and x (an array of step sizes)

%Define the step size as h and make an array of steps from 0 to n+2
for i = 0; i < n+2; i++{
    x[i] = h*double(i)
}

%Updating b-tilde and f-tilde using the equations we found using forward substitution
for i = 2; i < n+2; i++{
    btilde[i] = update
    ftilde[i] = update
}

%Updating u using the equations we found using backward substitution
for i = n; i > 0; i--{
    u[i] = update
}
%write the results to a file

\end{lstlisting}
%


\subsection{Specific algorithm}


%\begin{bmatrix}
%\Tilde{f}_1 \\
%\Tilde{f}_2 \\
%\dots \\
%\dots \\
%\dots \\
%\Tilde{f}_n
%\end{bmatrix}
%\end{array}
%


%
\begin{lstlisting}
%Allocate dynamic memory for variables, but a, b and c now have specific values
double a = -1; double b = 2; double c = -1
\end{lstlisting}

\begin{lstlisting}
%Updating b and f-tilde using the equations we found using forward substitution
for i = 2; i < n+2; i++{
    btilde[i] = update (a and c are now constants)
    ftilde[i] = update (a and c are now constants)
}

\end{lstlisting}
%

\subsection{LU-decomposition}

For a non-singular matrix $\boldsymbol{A} \in \R ^{nxn}$ we can also preform LU-decomposition, given by:
%
\[ \boldsymbol{A} = \boldsymbol{Lu} =
\begin{array}{c}
\begin{bmatrix}\label{eq:A = Lu}
l_{11}     & 0           & \dots         & 0       & 0 \\
l_{21}     & l_{22}           & 0       & \dots      & 0       \\
\dots       & \dots           & \dots       & \dots      & \dots    \\
\dots       & \dots           & \dots       & \dots      & 0    \\
 l_{n1} &  l_{n2}            & \dots        & l_{nn-1}      & l_{nn}     \\
\end{bmatrix}
\begin{bmatrix}
u_{11}     & u_{12}            & \dots         & \dots       & u_{1n} \\
0     & u_{22}           & \dots       & \dots      & u_{2n}       \\
\dots       & \dots           & \dots       & \dots      & \dots    \\
0       & \dots           & \dots       & \dots      & u_{(n-1)n}    \\
 0 &  0            & \dots        & 0      & u_{nn}     \\
\end{bmatrix}

\end{array}.
\]
%

%Summarize properties of data. Which data are used (experiment,frequencies etc.)? Pixel resolution ($N_{\textrm{side}}$),$\ell_{\textrm{max}}$ -- everything necessary to repeat the analysis for other researchers.

\section{Results}
\label{sec:results}
\subsection{Numerical error}

\begin{figure}[H]
\mbox{\epsfig{figure=filename.eps,width=\linewidth,clip=}}
\caption{The solution of the differential equation using a generalized algorithm, the three different plots show the $nxn$ matrix with $n=10$, $n=100$, $n=1000$}
\label{fig:figure_label}
\end{figure}

\begin{figure}[t]
\mbox{\epsfig{figure=plot1d.png,width=\linewidth,clip=}}
\caption{Vi burde plotte til 10^{-7}}
\label{fig:1d}
\end{figure}
%
\begin{deluxetable}{lc}[h]
%\tablewidth{0pt}
\tablecaption{\label{tab:results}}
\tablecomments{Table of log10 of the error, for stepsizes down to $10^{-7}$}
\tablecolumns{4}
\tablehead{Step size & Error}
\startdata
 \\
$10^{-1}$ & $10^{-1}$ \\
$10^{-2}$ & $10^{-1}$ \\
$10^{-3}$ & $10^{-1}$ \\
$10^{-4}$ & $10^{-1}$ \\
$10^{-5}$ & $10^{-1}$ \\
$10^{-6}$ & $10^{-1}$ \\
$10^{-7}$ & $10^{-1}$ \\
\enddata
\end{deluxetable}

%
\subsection{Program CPU time}

Testing the time we ran the three different programs 10 times for different sizes $n$, listing longest, shortest and average CPU times.
In [TABLE ] the results we have listed for timing our programs with $n = 1000$. Comparably for larger matrices $n=10^{6}$ the programs yield the timings presented in [TABLE ].
%
\begin{deluxetable}{lccc}[h]
%\tablewidth{0pt}
\tablecaption{\label{tab:results}}
\tablecomments{This table contains highest, lowest and average measured CPU times for the different algorithms used at n = 1000}
\tablecolumns{4}
\tablehead{ & General & Tailored & Armadillo}
\startdata
Highest & 10.8*10^{-5}s & 8.4*10^{-5}s & 0.012942s \\
Lowest & 3.4*10^{-5}s & 2.5*10^{-5}s & 0.007715s  \\
Average & 7.8*10^{-5}s & 5.5*10^{-5}s & 0.010166s 
\enddata
\end{deluxetable}
%
%
\begin{deluxetable}{lccc}[h]
%\tablewidth{0pt}
\tablecaption{\label{tab:results}}
\tablecomments{This table contains highest, lowest and average measured CPU times for the different algorithms used at n = 10^{6}}
\tablecolumns{4}
\tablehead{ & General & Tailored & Armadillo}
\startdata
Highest & 0.029865s & 0.028870s & Out of memory \\
Lowest & 0.027048s & 0.027058s & Out of memory  \\
Average & 0.027544s & 0.027602s & Out of memory 
\enddata
\end{deluxetable}
%

Note that the LU-decomposition runs out of memory at $n = 10^{5}$ meaning that we will not be able to test the Armadillo made algorithm for larger matrices.

\section{Conclusions}
\label{sec:conclusions}

%Summarize results. Discuss their importance, referring to the discovery to the initial seeds for structure formation. Mention that these results are in good agreement with expectations from inflationary theory.



%\begin{figure}[t]
%
%\mbox{\epsfig{figure=filename.eps,width=\linewidth,clip=}}
%
%\caption{Description of figure -- explain all elements, but do not
%draw conclusions here.}
%\label{fig:figure_label}
%\end{figure}


%\lstset{language=python,
%    showspaces=false,
%    extendedchars=true,
%    breaklines=true,
%    tabsize=2,
%    basicstyle=\small\ttfamily,
%    frame=single,
%    columns=flexible,
%    keepspaces=true,
%}
%\begin{lstlisting}
%\end{lstlisting}

%\begin{deluxetable}{lccc}
%\tablewidth{0pt}
%\tablecaption{\label{tab:results}}
%\tablecomments{Summary of main results.}
%\tablecolumns{4}
%\tablehead{Column 1  & Column 2 & Column 3 & Column 4}
%\startdata
%Item 1 & Item 2 & Item 3 & Item 4
%\enddata
%\end{deluxetable}



\begin{acknowledgements}

\end{acknowledgements}

\begin{thebibliography}{}

\bibitem[G{\'o}rski et al.(1994)]{gorski:1994} G{\'o}rski, K. M.,
  Hinshaw, G., Banday, A. J., Bennett, C. L., Wright, E. L., Kogut,
  A., Smoot, G. F., and Lubin, P.\ 1994, ApJL, 430, 89

\end{thebibliography}


\end{document}
